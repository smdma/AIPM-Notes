

## 人工神经网络

**人工神经网络（ Artificial Neural Network， 简写为ANN）也简称为神经网络（NN）**。是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）结构和功能的 **计算模型**。经典的神经网络结构包含三个层次的神经网络，**分别为输入层，输出层以及隐藏层。**

![网络结构](./images/网络结构.png)

**其中每层的圆圈代表一个神经元，隐藏层和输出层的神经元有输入的数据计算后输出，输入层的神经元只是输入。**

- 神经网络的特点
  - 每个连接都有个权值
  - 同一层神经元之间没有连接
  - 最后的输出结果对应的层也称之为**全连接层**

那么为什么设计这样的结构呢？首先从一个最基础的结构说起，神经元。以前也称之为感知机。神经元就是要模拟人的神经元结构。

> 一个神经元通常具有多个**树突**，主要用来接受传入信息；而**轴突**只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“**突触**”。

## 感知机

感知机(PLA: Perceptron Learning Algorithm)就是模拟大脑神经网络处理数据的过程。感知机模型如下图：

![感知机](./images/感知机.png)

感知机是一种最基础的分类模型，类似于逻辑回归，不同的是，感知机的激活函数用的是sign，而逻辑回归用的sigmoid。**感知机也具有连接的权重和偏置**

![感知机公式](./images/感知机公式.png)



**神经网络解决多分类问题最常用的方法是设置n个输出节点，其中n为类别的个数。**

### 模式识别

模式识别(Pattern Recognition)是指对表征事物或现象的各种形式的(数值的、文字的和逻辑关系的)信息进行处理和分析,以对事物或现象进行描述、辨认、分类和解释的过程,是信息科学和人工智能的重要组成部分。模式识别又常称作模式分类，从处理问题的性质和解决问题的方法等角度，模式识别分为有监督的分类（Supervised Classification）和无监督的分类(Unsupervised Classification)两种。

我们所指的模式识别主要是对语音波形、地震波、心电图、脑电图、图片、照片、文字、符号、生物传感器等对象的具体模式进行辨识和分类。模式识别研究主要集中在两方面,一是研究生物体(包括人)是如何感知对象的，属于认识科学的范畴，二是在给定的任务下,如何用计算机实现模式识别的理论和方法。

应用计算机对一组事件或过程进行辨识和分类，所识别的事件或过程可以是文字、声音、图像等具体对象，也可以是状态、程度等抽象对象。这些对象与数字形式的信息相区别，称为模式信息。它与人工智能、图像处理的研究有交叉关系。



### 玻尔兹曼机

玻尔兹曼机 Boltzmann machine

### Hopfield网络

Hopfield网络 Hopfield network

### 多层感知器

多层感知器 Multilayer perceptron

### 径向基函数网络（RBFN）

径向基函数网络（RBFN） Radial basis function network(RBFN)

### 受限玻尔兹曼机

受限玻尔兹曼机 Restricted Boltzmann machine

### 自组织映射（SOM）

自组织映射（SOM） Self-organizing map(SOM)

### 尖峰神经网络

尖峰神经网络 Spiking neural network

### 神经计算

神经计算科学是使用数学分析和计算机模拟的方法在不同水平上对神经系统进行模拟和研究：从神经元的真实生物物理模型，它们的动态交互关系以及神经网络的学习，到脑的组织和神经类型计算的量化理论等，从计算角度理解脑，研究非程序的、适应性的、大脑风格的信息处理的本质和能力，探索新型的信息处理机理和途径。

延伸阅读：[计算神经科学](https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E7%A5%9E%E7%BB%8F%E7%A7%91%E5%AD%A6/6749856)





## 反向传播BP

反向传播 Backpropagation



## softmax回归

Softmax回归（激活函数）将神经网络输出转换成概率结果。

类似于逻辑回归当中的sigmoid函数，sigmoid输出的是某个类别的概率。

![softmax公式](./images/softmax公式.png)

![softmax回归](./images/softmax回归.png)

![softmax展开](./images/softmax展开.png)

想一想线性回归的损失函数以及逻辑回归的损失函数，那么如何去衡量神经网络预测的概率分布和真实答案的概率分布之间的距离？

## 交叉熵损失

![交叉熵损失公式](./images/交叉熵损失公式.png)

为了能够衡量距离，目标值需要进行one-hot编码，能与概率值一一对应，如下图

![交叉损失理解](./images/交叉损失理解.png)

最后的损失为每个样本损失大小的平均值。

- sotfmax交叉熵适合于计算**类别相互排斥**的离散分类任务的损失值，每个输出对应一个类别。

  比如CIFAR-10图像都标**有一个且仅有一个标签**，只能是10个类别中的一种。

- sigmoid交叉熵适合计算**每个类别独立且不互相排斥**的离散分类任务中的损失值。

  例如，可以执行**多标签分类**，其中图片可以同时包含大象和狗。








## 线性神经网络的局限性
**多层的线性网络和单层的线性网络没有区别，而且线性模型的能够解决的问题也是有限的**。

一个单隐含层有更多的神经元，就能捕捉更多的特征。而且有更多隐层，意味着能从数据集中提取更多复杂的结构。

- 神经网络具有不可解释性（黑盒）。

- 训练深度神经网络需要大量的算力。

- 需要大量的训练数据集。一个强力的 GPU 服务器可能要花费数天、甚至数周的时间，才能使用数百万张图像的数据集训练出一个深度网络。而且，为了得到最好的训练结果，需要结合不同的网络设计与算法，并进行大量的试错。

**神经网络的种类：**

- 基础神经网络：线性神经网络，BP神经网络，Hopfield神经网络等﻿
- 进阶神经网络：玻尔兹曼机，受限玻尔兹曼机，递归神经网络等﻿
- 深度神经网络：深度置信网络，卷积神经网络，循环神经网络，LSTM网络等













